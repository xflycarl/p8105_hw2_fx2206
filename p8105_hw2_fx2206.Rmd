---
title: "p8105_hw2_fx2206"
author: "Fei Xue"
date: "2025-09-30"
output: github_document
---

```{r setup, message=FALSE, warning=FALSE}
library(tidyverse)
library(readxl)
library(janitor)
options(tibble.print_min = 5)
```

# Problem 1

## 1.1

```{r}
pols_month <- 
  read_csv("./fivethirtyeight_datasets/pols-month.csv", show_col_types = FALSE) |> 
  janitor::clean_names() |>
  separate(mon, into = c("year", "month", "day"), sep = "-") |>
  mutate(
    year = as.integer(year),
    month = as.integer(month),
    day = as.integer(day),
    month = month.abb[month],
    president = case_when(
      prez_gop == 1 ~ "gop",
      prez_dem == 1 ~ "dem",
      TRUE ~ NA_character_
    )
  ) |>
  select(-prez_dem, -prez_gop, -day)

pols_month
```

## 1.2

```{r}
snp <- 
  read_csv("./fivethirtyeight_datasets/snp.csv", show_col_types = FALSE) |>
  janitor::clean_names() |>
  separate(date, into = c("month", "day", "year"), sep = "/") |>
  mutate(
    year = as.integer(year),
    year = ifelse(year >= 50, 1900 + year, 2000 + year),
    month = as.integer(month),
    day = as.integer(day),
    month = month.abb[month]
  ) |>
  select(year, month, close) |>
  arrange(year, match(month, month.abb))

snp
```

## 1.3

```{r}
unemployment_tidy <- 
  read_csv("./fivethirtyeight_datasets/unemployment.csv", show_col_types = FALSE) |>
  pivot_longer(
    Jan:Dec,
    names_to = "month",
    values_to = "unemployment_rate"
  ) |>
  mutate(
    unemployment_rate = as.numeric(unemployment_rate)
  ) |>
  rename(year = Year)

unemployment_tidy
```

## 1.4

```{r}
d1 <- pols_month |>
  left_join(snp, by = c("year", "month")) |>
  left_join(unemployment_tidy, by = c("year", "month")) |>
  arrange(year, match(month, month.abb))

d1

# Create date variable version
d2 <- pols_month |>
  left_join(snp, by = c("year", "month")) |>
  left_join(unemployment_tidy, by = c("year", "month")) |>
  mutate(date = str_c(year, "-", sprintf("%02d", match(month, month.abb)))) |>
  relocate(date) |>
  select(-year, -month) |>
  arrange(date)

d2
```
The integrated dataset brings together information from three distinct sources covering political affiliations and economic metrics. Following individual data cleaning procedures, the pols-month data comprises 822 entries with 9 variables that document the counts of Democratic and Republican politicians at the federal level, capturing presidential party affiliations along with tallies of governors, senators, and representatives. The snp dataset includes 787 records with 3 variables that track the performance of the Standard & Poor's stock market index, providing monthly closing values with corresponding year and month identifiers. The unemployment component contains 816 observations with 3 variables measuring monthly unemployment percentages across different calendar years. The merged dataset maintains 822 monthly observations covering the period from 1947 through 2015 and incorporates 11 variables. Principal variables encompass temporal markers (year and month), political party distribution metrics (gov_gop, sen_gop, rep_gop, gov_dem, sen_dem, rep_dem), presidential party affiliation, S&P index closing figures, and unemployment rates. It should be noted that although the political data spans the entire 1947-2015 timeframe, the economic variables show gaps in the earlier years, with S&P records commencing in 1950 and unemployment data starting in 1948.

# Problem 2 â€” Trash Wheel
```{r}
#Read and clean the Mr. Trash Wheel sheet
mr_tidy <- read_excel("./trash_wheel.xlsx", 
                      sheet = "Mr. Trash Wheel", 
                      skip = 1,
                      na = c(".", "NA", "")) |>
  janitor::clean_names() |>
  filter(!is.na(dumpster)) |>
  mutate(
    sports_balls = as.integer(round(sports_balls)),
    year = as.integer(year),
    trash_wheel = "Mr. Trash Wheel"
  )

mr_tidy
#Read and clean Professor Trash Wheel data
professor_tidy <- read_excel('./trash_wheel.xlsx',
                             sheet = "Professor Trash Wheel",
                             skip = 1,
                             na = c('.', "NA", '')) |>
  janitor::clean_names() |>
  filter(!is.na(dumpster)) |>
  mutate(
    year = as.integer(year),
    trash_wheel = "Professor Trash Wheel"
  )

professor_tidy
#Read and clean Gwynnda data
gwynnda_tidy <- read_excel('./trash_wheel.xlsx',
                           sheet = "Gwynns Falls Trash Wheel", 
                           skip = 1,
                           na = c('.', "NA", '')) |>
  janitor::clean_names() |>
  filter(!is.na(dumpster)) |>
  mutate(
    year = as.integer(year),
    trash_wheel = "Gwynns Falls Trash Wheel"
  )

gwynnda_tidy

#combine
combined_trash <- bind_rows(mr_tidy, professor_tidy, gwynnda_tidy) |>
  select(-contains("...")) |>
  arrange(date)

combined_trash

# Total weight of trash collected by Professor Trash Wheel
prof_total_weight <- combined_trash |>
  filter(trash_wheel == "Professor Trash Wheel") |>
  summarize(total_weight = sum(weight_tons, na.rm = TRUE)) |>
  pull(total_weight)

# Total number of cigarette butts collected by Gwynnda in June 2022
gwynnda_cigarettes <- combined_trash |>
  filter(trash_wheel == "Gwynns Falls Trash Wheel", 
         year == 2022, 
         month == "June") |>
  summarize(total_cigarettes = sum(cigarette_butts, na.rm = TRUE)) |>
  pull(total_cigarettes)

prof_total_weight
gwynnda_cigarettes
```
The resulting dataset combines trash collection data from three separate devices operating in Baltimore's Inner Harbor: Mr. Trash Wheel, Professor Trash Wheel, and Gwynns Falls Trash Wheel. The resulting dataset contains `r nrow(combined_trash)` observations tracking waste collection with `r ncol(combined_trash)` variables. Key variables include dumpster identification numbers, collection dates, total weight of trash, the number of some specific waste categories such as plastic bottles, polystyrene, cigarette butts, and the trash wheel identifier to track the source device. (All the variables are: `r paste(names(combined_trash), collapse = ", "))`.

Based on the available data, the total weight of trash collected by Professor Trash Wheel is `r prof_total_weight` tons. During June 2022, Gwynns Falls Trash Wheel collected r gwynnda_cigarettes cigarette butts.

# Problem 3

```{r}
zip_codes_tidy <- read_csv("./zillow_data/Zip Codes.csv", 
                           na = c(".", "NA", "")) |>
  janitor::clean_names() |>
  relocate(zip_code) |>
  arrange(zip_code)

zip_codes_tidy

#Import and clean ZIP ZORI dataset
zip_zori <- read_csv("./zillow_data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv",
                     na = c(".", "NA", "")) |>
  janitor::clean_names()

zip_zori_tidy <- zip_zori |>
  pivot_longer(
    cols = starts_with('x20'),
    names_to = "date",
    values_to = "zori"
  ) |>
  mutate(
    date = str_remove(date, "^x"),
    date = str_replace_all(date, "_", "-")
  ) |>
  relocate(region_name) |>
  arrange(region_name)

zip_zori_tidy

#Merge to create final dataset
resulting_tidy_data <- zip_zori_tidy |>
  left_join(zip_codes_tidy, by = c("region_name" = "zip_code")) |>
  select(
    region_name, region_id, size_rank, region_type,
    state_name, state, city, metro, county,
    date, zori, county_code, county_fips, state_fips, file_date, neighborhood
  )

resulting_tidy_data

#Check for completeness
missing_zips <- zip_codes_tidy |>
  anti_join(zip_zori_tidy, by = c("zip_code" = "region_name")) |>
  select(zip_code, county, neighborhood)

missing_zips


```

How many total observations exist? How many unique ZIP codes are included, and how many unique neighborhoods?

The resulting tidy dataset contains `r nrow(resulting_tidy_data)` observations with `r ncol(resulting_tidy_data)` variables. The dataset spans from 2015-01-31 to 2024-08-31, providing a comprehensive time series of Zillow rental price. All the variables in this dataset are: `r paste(names(resulting_tidy_data), collapse = ", ")`.

Besides, the dataset includes `r n_distinct(resulting_tidy_data$region_name)` unique ZIP codes and `r n_distinct(na.omit(resulting_tidy_data$neighborhood))` unique neighborhoods across New York City. The structure also reveals that `r n_distinct(resulting_tidy_data$county)` distinct counties represented in the dataset.

Which ZIP codes appear in the ZIP code dataset but not in the Zillow Rental Price dataset? Using a few illustrative examples discuss why these ZIP codes might be excluded from the Zillow dataset.

There are `r nrow(missing_zips)` ZIP codes that appear in the ZIP code dataset but not in the Zillow Rental Price dataset. Examples include 10101, 10102, 10103, 10104, and 10105. The details of these examples are following:

10101, 10102, 10103, 10104, and 10105 are all located in Manhattan, specifically in areas that appear to be primarily commercial or institutional districts.

These ZIP codes correspond to the Midtown Manhattan area, which is dominated by office buildings, commercial establishments, and institutional facilities rather than residential housing.

These examples from Midtown Manhattan are likely excluded from the Zillow dataset for several reasons: firstly, these areas have very limited residential rental inventory due to their commercial nature, resulting in insufficient rental transaction data to calculate reliable ZORI values; secondly, the few residential units that do exist in these areas may be highly specialized (such as corporate housing or luxury condos) and not representative of the broader rental market; thirdly, Zillow's methodology requires a minimum threshold of rental data availability which these commercial-dominated ZIP codes may not meet.

```{r}
covid_rental <- resulting_tidy_data |>
  filter(date == "2020-01-31" | date == "2021-01-31") |>
  select(region_name, county, neighborhood, date, zori) |>
  pivot_wider(
    names_from = date,
    values_from = zori
  ) |>
  mutate(
    price_change = `2021-01-31` - `2020-01-31`,
    price_change_pct = (`2021-01-31` - `2020-01-31`) / `2020-01-31` * 100
  ) |>
  filter(!is.na(price_change)) |>
  arrange(price_change) |>
  head(10) |>
  rename(
    zip_code = region_name,
    borough = county,
    Jan_2020 = `2020-01-31`,
    Jan_2021 = `2021-01-31`
  ) |>
  select(zip_code, borough, neighborhood, Jan_2020, Jan_2021, price_change, price_change_pct)

cat("Top 10 ZIP codes with largest rental price drops from January 2020 to January 2021:\n")
covid_rental
```

The analysis reveals a pronounced pattern of rental price decreases concentrated primarily in Manhattan ZIP codes during the pandemic period. All ten areas with the most significant declines saw reductions between `r round(min(covid_rental$price_change_pct), 1)`% and `r round(max(covid_rental$price_change_pct), 1)`%, with the most substantial drop of `r round(max(covid_rental$price_change_pct), 1)`% observed in ZIP code `r covid_rental$zip_code[which.max(covid_rental$price_change_pct)]`. The geographic distribution of these declines highlights how Manhattan's core business and tourist districts were disproportionately affected. This trend likely reflects the substantial outmigration from dense urban centers as remote work arrangements became widespread, coupled with the sharp reduction in tourism and in-person office work that traditionally supported the rental market in these high-density neighborhoods.
